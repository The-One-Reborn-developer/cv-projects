{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "066375e0",
   "metadata": {},
   "source": [
    "# Car damage detection\n",
    "\n",
    "CV model that distinguishes between whole and damaged cars."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c597ea",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "Import the necessary modules.\n",
    "\n",
    "* pathlib: provide path to the dataset.\n",
    "* ImageDataLoaders: create a data block to be used in the CV model.\n",
    "* Resize: used to transform all images in the dataset into one uniform size before passing to the model.\n",
    "* aug_transforms: apply a set of default data augmentation transformations to the dataset. Helps with generalization of the model by introducing variations in training data.\n",
    "* vision_learner: build a vision learner from the data object.\n",
    "* resnet34: the model that will be used.\n",
    "* error_rate: metric for the human to validate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53603436-7015-4299-939c-e9ee0b0b18e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai.vision.all import (\n",
    "    ImageDataLoaders,\n",
    "    Resize,\n",
    "    aug_transforms,\n",
    "    vision_learner,\n",
    "    resnet34,\n",
    "    error_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10f3e55",
   "metadata": {},
   "source": [
    "### Variables\n",
    "\n",
    "1. Define the path to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b270ee-cc9a-4ace-a040-b9d8cf0982f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_string = kagglehub.dataset_download(\"anujms/car-damage-detection\")\n",
    "path = Path(path_string) / 'data1a'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a525b85",
   "metadata": {},
   "source": [
    "2. Define the data block for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d4652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_block = ImageDataLoaders.from_folder(\n",
    "    path,\n",
    "    'training',\n",
    "    'validation',\n",
    "    seed=42,\n",
    "    item_tfms=Resize(400),\n",
    "    batch_tfms=aug_transforms()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7147549",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Pass the defined data block to the vision learner for training. Fine tune it with the argument 1 (meaning one epoch or one whole pass through the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6835b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = vision_learner(data_block, resnet34, metrics=error_rate)\n",
    "learner.fine_tune(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba58b8a",
   "metadata": {},
   "source": [
    "Display the batch of the data to confirm visually that the training was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1244e984",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_block.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32116ed8",
   "metadata": {},
   "source": [
    "## Using\n",
    "\n",
    "Pass the image to the model to categorize it being either damaged or whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d864492",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Path('.') / 'test' / '5.jpg'\n",
    "learner.predict(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

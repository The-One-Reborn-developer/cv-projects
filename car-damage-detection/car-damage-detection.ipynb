{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "066375e0",
   "metadata": {},
   "source": [
    "# Car damage detection\n",
    "\n",
    "CV model that distinguishes between whole and damaged cars."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c597ea",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "Import the necessary modules.\n",
    "\n",
    "* kagglehub: used to download the dataset.\n",
    "* pathlib: provide path to the dataset.\n",
    "* ImageDataLoaders: create a data block to be used in the CV model.\n",
    "* Resize: used to transform all images in the dataset into one uniform size before passing to the model.\n",
    "* aug_transforms: apply a set of default data augmentation transformations to the dataset. Helps with generalization of the model by introducing variations in training data.\n",
    "* vision_learner: build a vision learner from the data object.\n",
    "* resnet34: the model that will be used.\n",
    "* error_rate: metric for the human to validate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53603436-7015-4299-939c-e9ee0b0b18e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kagglehub import dataset_download\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai.vision.all import (\n",
    "    ImageDataLoaders,\n",
    "    RandomResizedCrop,\n",
    "    aug_transforms,\n",
    "    vision_learner,\n",
    "    resnet34,\n",
    "    error_rate,\n",
    "    ClassificationInterpretation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10f3e55",
   "metadata": {},
   "source": [
    "### Variables\n",
    "\n",
    "1. Define the path to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b270ee-cc9a-4ace-a040-b9d8cf0982f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_string = dataset_download(\"anujms/car-damage-detection\")\n",
    "path = Path(path_string) / 'data1a'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a525b85",
   "metadata": {},
   "source": [
    "2. Define the data block for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d4652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_block = ImageDataLoaders.from_folder(\n",
    "    path,\n",
    "    'training',\n",
    "    'validation',\n",
    "    seed=42,\n",
    "    item_tfms=RandomResizedCrop(244, min_scale=0.5),\n",
    "    batch_tfms=aug_transforms()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7147549",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Pass the defined data block to the vision learner for training. Fine tune it with the argument 1 (meaning one epoch or one whole pass through the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6835b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = vision_learner(data_block, resnet34, metrics=error_rate)\n",
    "learner.fine_tune(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba58b8a",
   "metadata": {},
   "source": [
    "Display the batch of the data to confirm visually that the training was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab4cd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_block.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4011bd67-1891-4d2b-a185-77baae62cc05",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Interpreter can be used to visualize the results of training in a form of a confusion matrix.\n",
    "The numbers outside of the diagonal show how many samples the model got wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d864492",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = ClassificationInterpretation.from_learner(learner)\n",
    "interpreter.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3003c638-44fd-434d-b398-055b78923c09",
   "metadata": {},
   "source": [
    "This can be futher studied with the `plot_top_losses` method, which outputs the loss images with the caption: prediction/actual/loss/probability.\n",
    "\n",
    "The model is wrong with its prediction when either it predicted wrong (prediction and actual don't match) and is confident (high probability) or it predicted right (prediction and actual match) but it's not confident (low probability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2771a5a-6bcc-4d70-bcdd-a71b65ab5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.plot_top_losses(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32116ed8",
   "metadata": {},
   "source": [
    "## Using\n",
    "\n",
    "Pass the image to the model to categorize it being either damaged or whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d103dc-2ad3-4bdb-b0af-1d53a3ee9f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Path('.') / 'test' / '1.jpg'\n",
    "learner.predict(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

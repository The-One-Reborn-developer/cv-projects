{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit classifier\n",
    "\n",
    "A CV model that takes in an image of a digit as an input and classifies it from 0 to 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "* torch:\n",
    "* PIL.Image: open image files.\n",
    "* pathlib.Path: convert paths to directories/files to POSIXPath object that is convenient to use.\n",
    "* URLs: urls to different datasets.\n",
    "* untar_data: function to unarchive the dataset from the URLs.\n",
    "* tensor: function to convert image to its tensor representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "from fastai.vision.all import (\n",
    "    URLs,\n",
    "    untar_data,\n",
    "    tensor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "\n",
    "1. Define dataset path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_string = untar_data(URLs.MNIST)\n",
    "dataset_path = Path(dataset_path_string) / 'training'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define paths to each of the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroes = (dataset_path / '0').ls().sorted()\n",
    "ones = (dataset_path / '1').ls().sorted()\n",
    "twos = (dataset_path / '2').ls().sorted()\n",
    "threes = (dataset_path / '3').ls().sorted()\n",
    "fours = (dataset_path / '4').ls().sorted()\n",
    "fives = (dataset_path / '5').ls().sorted()\n",
    "sixs = (dataset_path / '6').ls().sorted()\n",
    "sevens = (dataset_path / '7').ls().sorted()\n",
    "eights = (dataset_path / '8').ls().sorted()\n",
    "nines = (dataset_path / '9').ls().sorted()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution\n",
    "\n",
    "#### Pixel Similarity\n",
    "\n",
    "Start with finding the average pixel value for each of the digits.\n",
    "\n",
    "1. Define rank 2 tensors (because the images are non colored, they have width and height dimensions, so the tensors are of rank 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroes_tensors_list = [tensor(Image.open(image)) for image in zeroes]\n",
    "ones_tensors_list = [tensor(Image.open(image)) for image in ones]\n",
    "twos_tensors_list = [tensor(Image.open(image)) for image in twos]\n",
    "threes_tensors_list = [tensor(Image.open(image)) for image in threes]\n",
    "fours_tensors_list = [tensor(Image.open(image)) for image in fours]\n",
    "fives_tensors_list = [tensor(Image.open(image)) for image in fives]\n",
    "sixs_tensors_list = [tensor(Image.open(image)) for image in sixs]\n",
    "sevens_tensors_list = [tensor(Image.open(image)) for image in sevens]\n",
    "eights_tensors_list = [tensor(Image.open(image)) for image in eights]\n",
    "nines_tensors_list = [tensor(Image.open(image)) for image in nines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Combine all the images in the tensors lists in a single rank 3 tensor (for each of the digits its own).\n",
    "Some operations in PyTorch require to cast variables to float, so it's done here.\n",
    "Since images when images are floats the pixels are expected to be in between 0 and 1, so also divide by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_zeroes = torch.stack(zeroes_tensors_list).float()/255\n",
    "stacked_ones = torch.stack(ones_tensors_list).float()/255\n",
    "stacked_twos = torch.stack(twos_tensors_list).float()/255\n",
    "stacked_threes = torch.stack(threes_tensors_list).float()/255\n",
    "stacked_fours = torch.stack(fours_tensors_list).float()/255\n",
    "stacked_fives = torch.stack(fives_tensors_list).float()/255\n",
    "stacked_sixs = torch.stack(sixs_tensors_list).float()/255\n",
    "stacked_sevens = torch.stack(sevens_tensors_list).float()/255\n",
    "stacked_eights = torch.stack(eights_tensors_list).float()/255\n",
    "stacked_nines = torch.stack(nines_tensors_list).float()/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Find the 'ideal' digit representation for each of the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroes_mean = stacked_zeroes.mean(0)\n",
    "ones_mean = stacked_ones.mean(0)\n",
    "twos_mean = stacked_twos.mean(0)\n",
    "threes_mean = stacked_threes.mean(0)\n",
    "fours_mean = stacked_fours.mean(0)\n",
    "fives_mean = stacked_fives.mean(0)\n",
    "sixs_mean = stacked_sixs.mean(0)\n",
    "sevens_mean = stacked_sevens.mean(0)\n",
    "eights_mean = stacked_eights.mean(0)\n",
    "nines_mean = stacked_nines.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create stacked tensors for the validation dataset to be able to calculate the accuracy metric over it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset_path = Path(dataset_path_string) / 'testing'\n",
    "\n",
    "validation_zeroes = (validation_dataset_path / '0').ls().sorted()\n",
    "validation_ones = (validation_dataset_path / '1').ls().sorted()\n",
    "validation_twos = (validation_dataset_path / '2').ls().sorted()\n",
    "validation_threes = (validation_dataset_path / '3').ls().sorted()\n",
    "validation_fours = (validation_dataset_path / '4').ls().sorted()\n",
    "validation_fives = (validation_dataset_path / '5').ls().sorted()\n",
    "validation_sixs = (validation_dataset_path / '6').ls().sorted()\n",
    "validation_sevens = (validation_dataset_path / '7').ls().sorted()\n",
    "validation_eights = (validation_dataset_path / '8').ls().sorted()\n",
    "validation_nines = (validation_dataset_path / '9').ls().sorted()\n",
    "\n",
    "validation_zeroes_tensors_list = [tensor(Image.open(image)) for image in validation_zeroes]\n",
    "validation_ones_tensors_list = [tensor(Image.open(image)) for image in validation_ones]\n",
    "validation_twos_tensors_list = [tensor(Image.open(image)) for image in validation_twos]\n",
    "validation_threes_tensors_list = [tensor(Image.open(image)) for image in validation_threes]\n",
    "validation_fours_tensors_list = [tensor(Image.open(image)) for image in validation_fours]\n",
    "validation_fives_tensors_list = [tensor(Image.open(image)) for image in validation_fives]\n",
    "validation_sixs_tensors_list = [tensor(Image.open(image)) for image in validation_sixs]\n",
    "validation_sevens_tensors_list = [tensor(Image.open(image)) for image in validation_sevens]\n",
    "validation_eights_tensors_list = [tensor(Image.open(image)) for image in validation_eights]\n",
    "validation_nines_tensors_list = [tensor(Image.open(image)) for image in validation_nines]\n",
    "\n",
    "validation_stacked_zeroes = torch.stack(validation_zeroes_tensors_list).float() / 255\n",
    "validation_stacked_ones = torch.stack(validation_ones_tensors_list).float() / 255\n",
    "validation_stacked_twos = torch.stack(validation_twos_tensors_list).float() / 255\n",
    "validation_stacked_threes = torch.stack(validation_threes_tensors_list).float() / 255\n",
    "validation_stacked_fours = torch.stack(validation_fours_tensors_list).float() / 255\n",
    "validation_stacked_fives = torch.stack(validation_fives_tensors_list).float() / 255\n",
    "validation_stacked_sixs = torch.stack(validation_sixs_tensors_list).float() / 255\n",
    "validation_stacked_sevens = torch.stack(validation_sevens_tensors_list).float() / 255\n",
    "validation_stacked_eights = torch.stack(validation_eights_tensors_list).float() / 255\n",
    "validation_stacked_nines = torch.stack(validation_nines_tensors_list).float() / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Define the function that will calculate the MAD of the independent digit to the mean of the same digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_distance(digit_tensor, ideal_mean_for_that_digit):\n",
    "    return (ideal_mean_for_that_digit - digit_tensor).abs().mean((-1, -2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Define functions that will calculate the MAD of the independent digit to the mean of all the digits in the training dataset and return whether the digit is it or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_zero(digit_tensor):\n",
    "    distances = torch.stack([\n",
    "        mnist_distance(digit_tensor, zeroes_mean),\n",
    "        mnist_distance(digit_tensor, ones_mean),\n",
    "        mnist_distance(digit_tensor, twos_mean),\n",
    "        mnist_distance(digit_tensor, threes_mean),\n",
    "        mnist_distance(digit_tensor, fours_mean),\n",
    "        mnist_distance(digit_tensor, fives_mean),\n",
    "        mnist_distance(digit_tensor, sixs_mean),\n",
    "        mnist_distance(digit_tensor, sevens_mean),\n",
    "        mnist_distance(digit_tensor, eights_mean),\n",
    "        mnist_distance(digit_tensor, nines_mean),\n",
    "    ])\n",
    "    closest_digit = distances.argmin(dim=0)\n",
    "    return closest_digit == 0\n",
    "\n",
    "def is_one(digit_tensor):\n",
    "    distances = torch.stack([\n",
    "        mnist_distance(digit_tensor, zeroes_mean),\n",
    "        mnist_distance(digit_tensor, ones_mean),\n",
    "        mnist_distance(digit_tensor, twos_mean),\n",
    "        mnist_distance(digit_tensor, threes_mean),\n",
    "        mnist_distance(digit_tensor, fours_mean),\n",
    "        mnist_distance(digit_tensor, fives_mean),\n",
    "        mnist_distance(digit_tensor, sixs_mean),\n",
    "        mnist_distance(digit_tensor, sevens_mean),\n",
    "        mnist_distance(digit_tensor, eights_mean),\n",
    "        mnist_distance(digit_tensor, nines_mean),\n",
    "    ])\n",
    "    closest_digit = distances.argmin(dim=0)\n",
    "    return closest_digit == 1\n",
    "\n",
    "def is_two(digit_tensor):\n",
    "    distances = torch.stack([\n",
    "        mnist_distance(digit_tensor, zeroes_mean),\n",
    "        mnist_distance(digit_tensor, ones_mean),\n",
    "        mnist_distance(digit_tensor, twos_mean),\n",
    "        mnist_distance(digit_tensor, threes_mean),\n",
    "        mnist_distance(digit_tensor, fours_mean),\n",
    "        mnist_distance(digit_tensor, fives_mean),\n",
    "        mnist_distance(digit_tensor, sixs_mean),\n",
    "        mnist_distance(digit_tensor, sevens_mean),\n",
    "        mnist_distance(digit_tensor, eights_mean),\n",
    "        mnist_distance(digit_tensor, nines_mean),\n",
    "    ])\n",
    "    closest_digit = distances.argmin(dim=0)\n",
    "    return closest_digit == 2\n",
    "\n",
    "def is_three(digit_tensor):\n",
    "    distances = torch.stack([\n",
    "        mnist_distance(digit_tensor, zeroes_mean),\n",
    "        mnist_distance(digit_tensor, ones_mean),\n",
    "        mnist_distance(digit_tensor, twos_mean),\n",
    "        mnist_distance(digit_tensor, threes_mean),\n",
    "        mnist_distance(digit_tensor, fours_mean),\n",
    "        mnist_distance(digit_tensor, fives_mean),\n",
    "        mnist_distance(digit_tensor, sixs_mean),\n",
    "        mnist_distance(digit_tensor, sevens_mean),\n",
    "        mnist_distance(digit_tensor, eights_mean),\n",
    "        mnist_distance(digit_tensor, nines_mean),\n",
    "    ])\n",
    "    closest_digit = distances.argmin(dim=0)\n",
    "    return closest_digit == 3\n",
    "\n",
    "def is_four(digit_tensor):\n",
    "    distances = torch.stack([\n",
    "        mnist_distance(digit_tensor, zeroes_mean),\n",
    "        mnist_distance(digit_tensor, ones_mean),\n",
    "        mnist_distance(digit_tensor, twos_mean),\n",
    "        mnist_distance(digit_tensor, threes_mean),\n",
    "        mnist_distance(digit_tensor, fours_mean),\n",
    "        mnist_distance(digit_tensor, fives_mean),\n",
    "        mnist_distance(digit_tensor, sixs_mean),\n",
    "        mnist_distance(digit_tensor, sevens_mean),\n",
    "        mnist_distance(digit_tensor, eights_mean),\n",
    "        mnist_distance(digit_tensor, nines_mean),\n",
    "    ])\n",
    "    closest_digit = distances.argmin(dim=0)\n",
    "    return closest_digit == 4\n",
    "\n",
    "def is_five(digit_tensor):\n",
    "    distances = torch.stack([\n",
    "        mnist_distance(digit_tensor, zeroes_mean),\n",
    "        mnist_distance(digit_tensor, ones_mean),\n",
    "        mnist_distance(digit_tensor, twos_mean),\n",
    "        mnist_distance(digit_tensor, threes_mean),\n",
    "        mnist_distance(digit_tensor, fours_mean),\n",
    "        mnist_distance(digit_tensor, fives_mean),\n",
    "        mnist_distance(digit_tensor, sixs_mean),\n",
    "        mnist_distance(digit_tensor, sevens_mean),\n",
    "        mnist_distance(digit_tensor, eights_mean),\n",
    "        mnist_distance(digit_tensor, nines_mean),\n",
    "    ])\n",
    "    closest_digit = distances.argmin(dim=0)\n",
    "    return closest_digit == 5\n",
    "\n",
    "def is_six(digit_tensor):\n",
    "    distances = torch.stack([\n",
    "        mnist_distance(digit_tensor, zeroes_mean),\n",
    "        mnist_distance(digit_tensor, ones_mean),\n",
    "        mnist_distance(digit_tensor, twos_mean),\n",
    "        mnist_distance(digit_tensor, threes_mean),\n",
    "        mnist_distance(digit_tensor, fours_mean),\n",
    "        mnist_distance(digit_tensor, fives_mean),\n",
    "        mnist_distance(digit_tensor, sixs_mean),\n",
    "        mnist_distance(digit_tensor, sevens_mean),\n",
    "        mnist_distance(digit_tensor, eights_mean),\n",
    "        mnist_distance(digit_tensor, nines_mean),\n",
    "    ])\n",
    "    closest_digit = distances.argmin(dim=0)\n",
    "    return closest_digit == 6\n",
    "\n",
    "def is_seven(digit_tensor):\n",
    "    distances = torch.stack([\n",
    "        mnist_distance(digit_tensor, zeroes_mean),\n",
    "        mnist_distance(digit_tensor, ones_mean),\n",
    "        mnist_distance(digit_tensor, twos_mean),\n",
    "        mnist_distance(digit_tensor, threes_mean),\n",
    "        mnist_distance(digit_tensor, fours_mean),\n",
    "        mnist_distance(digit_tensor, fives_mean),\n",
    "        mnist_distance(digit_tensor, sixs_mean),\n",
    "        mnist_distance(digit_tensor, sevens_mean),\n",
    "        mnist_distance(digit_tensor, eights_mean),\n",
    "        mnist_distance(digit_tensor, nines_mean),\n",
    "    ])\n",
    "    closest_digit = distances.argmin(dim=0)\n",
    "    return closest_digit == 7\n",
    "\n",
    "def is_eight(digit_tensor):\n",
    "    distances = torch.stack([\n",
    "        mnist_distance(digit_tensor, zeroes_mean),\n",
    "        mnist_distance(digit_tensor, ones_mean),\n",
    "        mnist_distance(digit_tensor, twos_mean),\n",
    "        mnist_distance(digit_tensor, threes_mean),\n",
    "        mnist_distance(digit_tensor, fours_mean),\n",
    "        mnist_distance(digit_tensor, fives_mean),\n",
    "        mnist_distance(digit_tensor, sixs_mean),\n",
    "        mnist_distance(digit_tensor, sevens_mean),\n",
    "        mnist_distance(digit_tensor, eights_mean),\n",
    "        mnist_distance(digit_tensor, nines_mean),\n",
    "    ])\n",
    "    closest_digit = distances.argmin(dim=0)\n",
    "    return closest_digit == 8\n",
    "\n",
    "def is_nine(digit_tensor):\n",
    "    distances = torch.stack([\n",
    "        mnist_distance(digit_tensor, zeroes_mean),\n",
    "        mnist_distance(digit_tensor, ones_mean),\n",
    "        mnist_distance(digit_tensor, twos_mean),\n",
    "        mnist_distance(digit_tensor, threes_mean),\n",
    "        mnist_distance(digit_tensor, fours_mean),\n",
    "        mnist_distance(digit_tensor, fives_mean),\n",
    "        mnist_distance(digit_tensor, sixs_mean),\n",
    "        mnist_distance(digit_tensor, sevens_mean),\n",
    "        mnist_distance(digit_tensor, eights_mean),\n",
    "        mnist_distance(digit_tensor, nines_mean),\n",
    "    ])\n",
    "    closest_digit = distances.argmin(dim=0)\n",
    "    return closest_digit == 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Calculate accuracy of the model for the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_zeroes = is_zero(validation_stacked_zeroes).float().mean()\n",
    "accuracy_ones = is_one(validation_stacked_ones).float().mean()\n",
    "accuracy_twos = is_two(validation_stacked_twos).float().mean()\n",
    "accuracy_threes = is_three(validation_stacked_threes).float().mean()\n",
    "accuracy_fours = is_four(validation_stacked_fours).float().mean()\n",
    "accuracy_fives = is_five(validation_stacked_fives).float().mean()\n",
    "accuracy_sixs = is_six(validation_stacked_sixs).float().mean()\n",
    "accuracy_sevens = is_seven(validation_stacked_sevens).float().mean()\n",
    "accuracy_eights = is_eight(validation_stacked_eights).float().mean()\n",
    "accuracy_nines = is_nine(validation_stacked_nines).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(time, parameters):\n",
    "    a, b, c = parameters\n",
    "    return a*(time**2) + (b*time) + c\n",
    "\n",
    "def mse(prediction, target):\n",
    "    return ((prediction - target)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = torch.arange(0, 20).float()\n",
    "speed = torch.randn(20)*3 + 0.75*(time-9.5)**2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = torch.randn(3).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_parameters = parameters.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = f(time, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(predictions, ax=None):\n",
    "    if ax is None:\n",
    "        ax=plot.subplots()[1]\n",
    "    ax.scatter(time, speed)\n",
    "    ax.scatter(time, predictions.detach().cpu().numpy(), color='red')\n",
    "    ax.set_ylim(-300, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = mse(predictions, speed)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters.grad * 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "parameters.data -= lr * parameters.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = f(time, parameters)\n",
    "mse(predictions, speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_step(parameters, prn=True):\n",
    "    predictions = f(time, parameters)\n",
    "    loss = mse(predictions, speed)\n",
    "    loss.backward()\n",
    "    parameters.data -= lr * parameters.grad.data\n",
    "    parameters.grad = None\n",
    "    if prn:\n",
    "        print(loss.item())\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    apply_step(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = original_parameters.detach().requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plot.subplots(1, 4, figsize=(12, 3))\n",
    "for ax in axs:\n",
    "    show_predictions(apply_step(parameters, False), ax)\n",
    "plot.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
